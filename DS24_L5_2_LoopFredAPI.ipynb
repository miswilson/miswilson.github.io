{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMdEP5tUEczQYpbifVDVmp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"n4ORRLYQ459W"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["**Richard Davies** Data Science - 2024 - Loop with FRED API\n","\n","With knowedge of loops in place, we examine how they can be used in data science contexts.\n","\n","In this case we will run through a list of data series in order to provide multiple requests to an API, batch downloading this data."],"metadata":{"id":"ODpNqMOG5JdS"}},{"cell_type":"markdown","metadata":{"id":"DKg2vT3ObIHp"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"WNP3NmHAo8aj"},"source":["<br>\n","<br>\n","\n","### Looping with an API: FRED\n","\n","With these buliding blocks in place, lets build something that may actually be useful. Imagine you cover the US Economy as an analyst. You make a weekly dashboard. This must take in 10 important series, each of them plotted with a line chart. The data will need to be re-downloaded each week, meaning that you are manually downloading 520 series per year, in order to keep your dashboard up to date. How can we batch process this, so that all downloads are done with one click? <br>\n","\n","<br>\n","\n","First, we need a list of FRED series we want to download. We'll create a list of the series codes we want data for.\n","\n","For example, FRED series for GDP and unemployment are: <br>\n","https://fred.stlouisfed.org/series/GDP <br>\n","https://fred.stlouisfed.org/series/UNRATE\n","\n"," *Note: Since these are codes are made up of letters and numbers, they must be string type (i.e. surrounded by \" \" or ' ' quotes), you can learn more about Python data types [here](https://www.w3schools.com/python/python_datatypes.asp)*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1N4WWnGOsrox"},"outputs":[],"source":["# Write out my list of series:\n","fred_series = ['GDP', 'PCEPI', 'CPIAUCSL', 'PAYEMS', 'DGS10', 'INDPRO', 'UNRATE']\n","\n","# // Set the base url:\n","url_base = \"https://api.stlouisfed.org/fred/series/observations?series_id={}&api_key=22ee7a76e736e32f54f5df0a7171538d&file_type=json\"\n","\n","for i in fred_series:\n","  # Print the series code we're about to download.\n","  print(i)\n","\n","  # Build the URL for this iteration of the loop, and check what we are getting:\n","  URL = url_base.format(i)\n","  print(URL)\n","\n","  # Add some white space to our output. (This is purely so we can see what is happening below clearly)\n","  print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"OfIEAj9js56W"},"source":["<br>\n","<br>\n","\n","### Batch downloader: FRED.\n","We are now ready to build out batch downloader. The code below\n","\n","1. Accesses some Python packages that we will need.\n","2. Sets up (defines) the elements we will use over and over again in our loop.\n","3. Runs the loop itself."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPyxrJu4ARZp"},"outputs":[],"source":["# // FIRST BATCH DOWNLOADER\n","\n","\n","# 1. PREPARATORY STEPS - ACCESS PACKAGES WE NEED\n","\n","## // The \"requests\" package, for opening web sites and retrieving information:\n","import requests\n","\n","## // The \"json\" package, for helping us make JSON easier to read:\n","import json\n","\n","\n","## ------\n","\n","# 2. SETTING UP THE ELEMENTS WE NEED IN OUR LOOP:\n","\n","# // Pick the series that I want:\n","fred_series = ['GDP', 'PCEPI', 'CPIAUCSL', 'PAYEMS', 'DGS10', 'INDPRO', 'UNRATE']\n","\n","# // Set the base url:\n","url_base = \"https://api.stlouisfed.org/fred/series/observations?series_id={}&api_key=22ee7a76e736e32f54f5df0a7171538d&file_type=json\"\n","\n","# // Set a base fileName:\n","file_base = \"data_FRED-{}.json\"\n","\n","## ------\n","\n","# 3. USING THE ABOVE TO RUN A LOOP:\n","\n","# // Begin a loop, dealing with each series, one by one:\n","for i in fred_series:\n","\n","    # // Print some text to make clear when iteration starts and ends:\n","    # // This is not necessary but can be helpful, esp with long loops:\n","    print(\"------Iteration Starts--------\")\n","    print(i)\n","\n","    # // Build the URL for this iteration of the loop, print it to check what we are getting:\n","    URL = url_base.format(i)\n","    print(URL)\n","\n","    # // Request the html from the URL, and format as JSON:\n","    data = requests.get(URL).json()\n","\n","    # // Build the filename. Print it to check what we are getting:\n","    fileName = file_base.format(i)\n","    print('Series we are downloading is', i)\n","    print('Data saved to', fileName)\n","\n","    # /// Save the file:\n","    with open(fileName, 'w', encoding='utf-8') as f:\n","        json.dump(data, f, ensure_ascii=False, indent=4)\n","\n","\n","    # // Add some white space to our output. (This is purely so we can see what is happening below clearly)\n","    print(\"------Iteration Ends--------\\n\")"]},{"cell_type":"markdown","metadata":{"id":"AHnOwdz5cg51"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"-sWeAynBksJF"},"source":[]}]}